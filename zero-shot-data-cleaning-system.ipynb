{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8839929",
   "metadata": {
    "papermill": {
     "duration": 0.007049,
     "end_time": "2025-11-26T04:59:44.318997",
     "exception": false,
     "start_time": "2025-11-26T04:59:44.311948",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Why Develop the Zero-Shot Data Cleaning System?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f59e0b9",
   "metadata": {
    "papermill": {
     "duration": 0.00565,
     "end_time": "2025-11-26T04:59:44.330847",
     "exception": false,
     "start_time": "2025-11-26T04:59:44.325197",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### The primary reason for developing this multi-agent system is to eliminate the single largest bottleneck in data science and analytics: manual, brittle, and non-reusable data cleaning.\n",
    "\n",
    "*ðŸ›‘ **Pain Point:** Manual data cleaning is slow, error-prone, and non-reusable, bottlenecking data science with custom scripts and creating technical debt.*\n",
    "\n",
    "*âœ… **The Goal:** The system aims for true zero-shot automation by having the AI Planner instantly write and adapt the cleaning script for any unseen dataset.* \n",
    "\n",
    "*ðŸ’° **Core Benefit:** The multi-agent design ensures consistency, speed, and a drastic cost reduction, freeing data scientists to focus on modeling instead of remediation.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44b0656",
   "metadata": {
    "papermill": {
     "duration": 0.005614,
     "end_time": "2025-11-26T04:59:44.342283",
     "exception": false,
     "start_time": "2025-11-26T04:59:44.336669",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# How to Build the System"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59b150a",
   "metadata": {
    "papermill": {
     "duration": 0.006104,
     "end_time": "2025-11-26T04:59:44.354180",
     "exception": false,
     "start_time": "2025-11-26T04:59:44.348076",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### The Zero-Shot Data Cleaning architecture separates the LLM's cleaning decisions (creative) from the code's execution (reliable) into three controllable phases\n",
    "\n",
    "***Define the Contract (Schema):** Establish a strict JSON schema (e.g., Pydantic) that dictates the only valid cleaning commands the LLM can suggest, ensuring predictable communication.*\n",
    "\n",
    "***Build the Executor (Tools):** Write deterministic, tested code functions to reliably execute every command defined in the contract, creating the non-negotiable core transformation engine.*\n",
    "\n",
    "***Integrate and Orchestrate:** Use the LLM to generate the plan (a sequence of commands) and use the Executor to run the steps sequentially against the data, connecting intelligence to action.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08372cd4",
   "metadata": {
    "papermill": {
     "duration": 0.005743,
     "end_time": "2025-11-26T04:59:44.365687",
     "exception": false,
     "start_time": "2025-11-26T04:59:44.359944",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Imports Libraries & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "395e94ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T04:59:44.378543Z",
     "iopub.status.busy": "2025-11-26T04:59:44.378212Z",
     "iopub.status.idle": "2025-11-26T04:59:46.402884Z",
     "shell.execute_reply": "2025-11-26T04:59:46.402154Z"
    },
    "papermill": {
     "duration": 2.032863,
     "end_time": "2025-11-26T04:59:46.404355",
     "exception": false,
     "start_time": "2025-11-26T04:59:44.371492",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import Optional, List, Dict, Any, Tuple, Callable,Literal\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b001334",
   "metadata": {
    "papermill": {
     "duration": 0.00567,
     "end_time": "2025-11-26T04:59:46.416058",
     "exception": false,
     "start_time": "2025-11-26T04:59:46.410388",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# External Data Loader Dependency Check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c7b4a1",
   "metadata": {
    "papermill": {
     "duration": 0.005574,
     "end_time": "2025-11-26T04:59:46.427286",
     "exception": false,
     "start_time": "2025-11-26T04:59:46.421712",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "*This code exists to check for the external dependency (kagglehub) required to load data from Kaggle.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fb6896a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T04:59:46.441143Z",
     "iopub.status.busy": "2025-11-26T04:59:46.440067Z",
     "iopub.status.idle": "2025-11-26T04:59:46.760491Z",
     "shell.execute_reply": "2025-11-26T04:59:46.759447Z"
    },
    "papermill": {
     "duration": 0.328548,
     "end_time": "2025-11-26T04:59:46.761923",
     "exception": false,
     "start_time": "2025-11-26T04:59:46.433375",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUCCESS: 'kagglehub' imported successfully.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from kagglehub import dataset_download\n",
    "    print(\"SUCCESS: 'kagglehub' imported successfully.\")\n",
    "    KAGGLEHUB_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print(\"WARNING: 'kagglehub' not found. Data loading from Kaggle will fail.\")\n",
    "    # Define a dummy function to prevent runtime errors if not installed\n",
    "    def dataset_download(id):\n",
    "        raise ImportError(\"kagglehub not installed.\")\n",
    "    KAGGLEHUB_AVAILABLE = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b9ebd8",
   "metadata": {
    "papermill": {
     "duration": 0.005818,
     "end_time": "2025-11-26T04:59:46.773899",
     "exception": false,
     "start_time": "2025-11-26T04:59:46.768081",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Global Data Constants & Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f504a8",
   "metadata": {
    "papermill": {
     "duration": 0.005867,
     "end_time": "2025-11-26T04:59:46.785655",
     "exception": false,
     "start_time": "2025-11-26T04:59:46.779788",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "*These constants define the source Kaggle dataset, the specific CSV file to extract from it, and the local file path where the final cleaned data will be saved*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcb76d74",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T04:59:46.798995Z",
     "iopub.status.busy": "2025-11-26T04:59:46.798376Z",
     "iopub.status.idle": "2025-11-26T04:59:46.802505Z",
     "shell.execute_reply": "2025-11-26T04:59:46.801666Z"
    },
    "papermill": {
     "duration": 0.0123,
     "end_time": "2025-11-26T04:59:46.803803",
     "exception": false,
     "start_time": "2025-11-26T04:59:46.791503",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- Global Constants & Setup ---\n",
    "KAGGLE_DATASET_ID = \"praveensoni06/1500-latest-movies-datasets-2025\"\n",
    "CSV_FILE_NAME = \"Latest 2025 movies Datasets.csv\" # The file name expected inside the archive\n",
    "OUTPUT_FILE_PATH = \"cleaned_movies_data.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178bcb2f",
   "metadata": {
    "papermill": {
     "duration": 0.005953,
     "end_time": "2025-11-26T04:59:46.815861",
     "exception": false,
     "start_time": "2025-11-26T04:59:46.809908",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "***--- IMPORTANT NOTE FOR DATASET CHANGES ---***\n",
    "\n",
    "*If you wish to use a different Kaggle dataset:*\n",
    "1. Update KAGGLE_DATASET_ID with the 'user_name/dataset_name' found on Kaggle.\n",
    "2.  Update CSV_FILE_NAME with the exact .csv file name that is present INSIDE the downloaded Kaggle archive.\n",
    "3. Adjust OUTPUT_FILE_PATH if you want a different name for the cleaned data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a61b22",
   "metadata": {
    "papermill": {
     "duration": 0.005927,
     "end_time": "2025-11-26T04:59:46.827617",
     "exception": false,
     "start_time": "2025-11-26T04:59:46.821690",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# The A2A Communication Protocol"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe94d53",
   "metadata": {
    "papermill": {
     "duration": 0.005747,
     "end_time": "2025-11-26T04:59:46.839287",
     "exception": false,
     "start_time": "2025-11-26T04:59:46.833540",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## The Agent Language (Pydantic Models):\n",
    "\n",
    "*These Pydantic models create a strict, JSON-based communication protocol for the AI agents, ensuring the Planner's instructions (e.g., cleaning actions) are always perfectly understood and executable by the Executor.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65ef40b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T04:59:46.853175Z",
     "iopub.status.busy": "2025-11-26T04:59:46.852589Z",
     "iopub.status.idle": "2025-11-26T04:59:46.901992Z",
     "shell.execute_reply": "2025-11-26T04:59:46.901111Z"
    },
    "papermill": {
     "duration": 0.058097,
     "end_time": "2025-11-26T04:59:46.903417",
     "exception": false,
     "start_time": "2025-11-26T04:59:46.845320",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Agent Protocol Models Defined ---\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------------------------------\n",
    "# 1. AGENT PROTOCOL DATA MODELS (Pydantic Schemas)\n",
    "# ----------------------------------------------------\n",
    "CleaningOperation = Literal[\"impute_missing\", \"remove_duplicates\", \"convert_datatype\", \"standardize_case\", \"drop_column\"]\n",
    "ImputationMethod = Literal[\"mean\", \"median\", \"mode\", \"drop\"]\n",
    "CaseMethod = Literal[\"titlecase\", \"lowercase\", \"uppercase\"]\n",
    "DataType = Literal[\"int\", \"float\", \"datetime\", \"str\"]\n",
    "\n",
    "class CleaningAction(BaseModel):\n",
    "    method: str = Field(..., description=\"The specific method for the operation (e.g., 'median', 'lowercase', 'datetime').\")\n",
    "    operation: str = Field(..., description=\"The name of the tool/operation to execute (e.g., 'impute_missing').\")\n",
    "    column: Optional[str] = Field(None, description=\"The specific column to target. Omit for DataFrame-wide operations.\")\n",
    "    method: str = Field(..., description=\"The specific method for the operation (e.g., 'median', 'lowercase', 'datetime').\")\n",
    "    rationale: str = Field(..., description=\"The LLM's reasoning for this action, used for the final report.\")\n",
    "    execution_metrics: Dict[str, Any] = Field(default_factory=dict, description=\"Metrics generated during execution.\")\n",
    "\n",
    "class CleaningPlan(BaseModel):\n",
    "    \"\"\"The complete plan generated by the Planner Agent.\"\"\"\n",
    "    actions: List[CleaningAction] = Field(..., description=\"An ordered list of cleaning actions to be executed.\")\n",
    "\n",
    "class VerificationReport(BaseModel):\n",
    "    \"\"\"The final report generated by the Verifier Agent.\"\"\"\n",
    "    confidence_score: float = Field(..., description=\"Overall confidence score (0.0 to 1.0) in the data quality after cleaning.\")\n",
    "    summary_of_changes: Dict[str, Any] = Field(..., description=\"Metrics like rows dropped, nulls reduced, etc.\")\n",
    "    flags: List[str] = Field(..., description=\"List of warnings or failures identified during verification.\")\n",
    "    recommendation: str = Field(..., description=\"Final recommendation for using the cleaned data.\")\n",
    "\n",
    "print(\"--- Agent Protocol Models Defined ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e5a7cf",
   "metadata": {
    "papermill": {
     "duration": 0.005885,
     "end_time": "2025-11-26T04:59:46.915422",
     "exception": false,
     "start_time": "2025-11-26T04:59:46.909537",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Utiliy & Profiler Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03c8b43",
   "metadata": {
    "papermill": {
     "duration": 0.005805,
     "end_time": "2025-11-26T04:59:46.927065",
     "exception": false,
     "start_time": "2025-11-26T04:59:46.921260",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Loader Agent: Data Ingestion and Sanitization\n",
    "\n",
    "*This function handles the robust downloading of the dataset from Kaggle, file path resolution, and initial data loading. Critically, it converts various common string representations of missing values (like 'N/A', '?', or empty strings) into standard np.nan for accurate downstream analysis.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87ee6081",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T04:59:46.941105Z",
     "iopub.status.busy": "2025-11-26T04:59:46.940353Z",
     "iopub.status.idle": "2025-11-26T04:59:46.949045Z",
     "shell.execute_reply": "2025-11-26T04:59:46.948132Z"
    },
    "papermill": {
     "duration": 0.01738,
     "end_time": "2025-11-26T04:59:46.950390",
     "exception": false,
     "start_time": "2025-11-26T04:59:46.933010",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Loader Agent (load_data) function defined successfully ---\n"
     ]
    }
   ],
   "source": [
    "def load_data(kaggle_id: str, csv_name: str) -> Optional[pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    [Loader Agent Logic] Downloads data from Kaggle, loads it, and robustly \n",
    "    converts common null strings into proper np.nan for accurate profiling.\n",
    "    \"\"\"\n",
    "    print(f\"--- Loader Agent Activated: Downloading dataset {kaggle_id} ---\")\n",
    "    try:\n",
    "        # Download the dataset using kagglehub\n",
    "        download_dir = dataset_download(kaggle_id) \n",
    "        print(f\" > Dataset downloaded to: {download_dir}\")\n",
    "\n",
    "        # Use glob to find the CSV file robustly, even if nested\n",
    "        csv_files = glob(os.path.join(download_dir, '**', csv_name), recursive=True)\n",
    "        \n",
    "        if csv_files:\n",
    "            data_path = csv_files[0]\n",
    "            print(f\" > File found at: {data_path}\")\n",
    "        else:\n",
    "            # Fallback: Search for *any* CSV file\n",
    "            csv_files_wildcard = glob(os.path.join(download_dir, '**', '*.csv'), recursive=True)\n",
    "            if csv_files_wildcard:\n",
    "                data_path = csv_files_wildcard[0]\n",
    "                print(f\" > WARNING: Used fallback to load first CSV found: {os.path.basename(data_path)}\")\n",
    "            else:\n",
    "                raise FileNotFoundError(f\"Could not find the confirmed CSV file '{csv_name}' or any other CSV file in the downloaded archive.\")\n",
    "\n",
    "        # Load the data, using standard pandas NA values and specifying others\n",
    "        na_values_to_recognize = [\n",
    "            'N/A', 'NA', 'NaN', 'null', 'None', '?', '-', ' '\n",
    "        ]\n",
    "        df = pd.read_csv(data_path, na_values=na_values_to_recognize)\n",
    "        \n",
    "        # Explicitly convert empty strings which often bypass na_values in some files\n",
    "        df = df.replace(r'^\\s*$', np.nan, regex=True)\n",
    "        \n",
    "        initial_shape = df.shape\n",
    "        initial_null_count = df.isnull().sum().sum()\n",
    "        \n",
    "        print(f\" > Data loaded successfully.\")\n",
    "        print(f\" > Initial shape: {initial_shape}. Detected NaN count: {initial_null_count}\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"!!! CRITICAL ERROR: Data ingestion failed. Error: {e}\")\n",
    "        return None\n",
    "print(\"--- Loader Agent (load_data) function defined successfully ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13959942",
   "metadata": {
    "papermill": {
     "duration": 0.00603,
     "end_time": "2025-11-26T04:59:46.962635",
     "exception": false,
     "start_time": "2025-11-26T04:59:46.956605",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Utility Function: Saving Final Output\n",
    "\n",
    "*This simple utility function (save_cleaned_data) is responsible for saving the final processed and cleaned DataFrame to the specified OUTPUT_FILE_PATH on disk.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3bf0b509",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T04:59:46.976487Z",
     "iopub.status.busy": "2025-11-26T04:59:46.976167Z",
     "iopub.status.idle": "2025-11-26T04:59:46.981880Z",
     "shell.execute_reply": "2025-11-26T04:59:46.981022Z"
    },
    "papermill": {
     "duration": 0.014408,
     "end_time": "2025-11-26T04:59:46.983116",
     "exception": false,
     "start_time": "2025-11-26T04:59:46.968708",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Utility Function (save_cleaned_data) defined successfully ---\n"
     ]
    }
   ],
   "source": [
    "def save_cleaned_data(df: pd.DataFrame, file_path: str):\n",
    "    \"\"\"Saves the final cleaned DataFrame.\"\"\"\n",
    "    try:\n",
    "        OUTPUT_DIR_NAME = os.path.dirname(file_path) or \".\"\n",
    "        os.makedirs(OUTPUT_DIR_NAME, exist_ok=True)\n",
    "        df.to_csv(file_path, index=False)\n",
    "        print(f\"\\n > Cleaned data successfully saved to: {file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"!!! SAVER FAILED: {e}\")\n",
    "print(\"--- Utility Function (save_cleaned_data) defined successfully ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3bdd15",
   "metadata": {
    "papermill": {
     "duration": 0.005919,
     "end_time": "2025-11-26T04:59:46.995377",
     "exception": false,
     "start_time": "2025-11-26T04:59:46.989458",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Profiler Agent: Data Observation and Summary Generation\n",
    "\n",
    "*The core of the observation phase, this function analyzes the loaded data, calculating critical quality metrics like total missing values, column-specific null percentages, and data types. It packages this condensed statistical summary into a JSON-like format for the Planner Agent.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d137a556",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T04:59:47.009217Z",
     "iopub.status.busy": "2025-11-26T04:59:47.008929Z",
     "iopub.status.idle": "2025-11-26T04:59:47.017004Z",
     "shell.execute_reply": "2025-11-26T04:59:47.016031Z"
    },
    "papermill": {
     "duration": 0.016774,
     "end_time": "2025-11-26T04:59:47.018210",
     "exception": false,
     "start_time": "2025-11-26T04:59:47.001436",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Profiler Agent (profile_data) function defined successfully ---\n"
     ]
    }
   ],
   "source": [
    "def profile_data(df: pd.DataFrame) -> Dict[str, Any]:\n",
    "    \"\"\"[Profiler Agent Logic] Generates a compact summary of data quality issues.\"\"\"\n",
    "    print(\"\\n--- Profiler Agent (Observer) Activated ---\")\n",
    "    \n",
    "    # 1. Basic Stats\n",
    "    total_cells = np.prod(df.shape)\n",
    "    total_null_count = df.isnull().sum().sum()\n",
    "\n",
    "    # 2. Detailed Column Stats\n",
    "    column_details = {}\n",
    "    for col in df.columns:\n",
    "        null_count = df[col].isnull().sum()\n",
    "        null_percent = (null_count / len(df)) * 100\n",
    "        unique_count = df[col].nunique()\n",
    "        column_details[col] = {\n",
    "            'dtype': str(df[col].dtype),\n",
    "            'missing_values': int(null_count),\n",
    "            'missing_percent': round(null_percent, 2),\n",
    "            'unique_values': int(unique_count),\n",
    "            'example_values': [str(x) for x in df[col].dropna().head(2).tolist()]\n",
    "        }\n",
    "\n",
    "    # 3. Compile Summary (Context Compaction for LLM)\n",
    "    summary = {\n",
    "        'shape': df.shape,\n",
    "        'total_null_percentage': round((total_null_count / total_cells) * 100, 2),\n",
    "        'missing_values_by_column': {k: v['missing_values'] for k, v in column_details.items() if v['missing_values'] > 0},\n",
    "        'columns': column_details\n",
    "    }\n",
    "    print(\" > Data profiling complete. Summary generated for Planner Agent.\")\n",
    "    return summary\n",
    "\n",
    "print(\"--- Profiler Agent (profile_data) function defined successfully ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6e99d9",
   "metadata": {
    "papermill": {
     "duration": 0.006198,
     "end_time": "2025-11-26T04:59:47.030902",
     "exception": false,
     "start_time": "2025-11-26T04:59:47.024704",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Executor Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f514787f",
   "metadata": {
    "papermill": {
     "duration": 0.006059,
     "end_time": "2025-11-26T04:59:47.043166",
     "exception": false,
     "start_time": "2025-11-26T04:59:47.037107",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Deduplication and Imputation Tools\n",
    "\n",
    "*Contains functions to remove duplicate rows (tool_deduplicate) and intelligently fill in missing data using mean, median, or most frequent values (tool_impute_missing).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27b741e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T04:59:47.057028Z",
     "iopub.status.busy": "2025-11-26T04:59:47.056754Z",
     "iopub.status.idle": "2025-11-26T04:59:47.072020Z",
     "shell.execute_reply": "2025-11-26T04:59:47.071133Z"
    },
    "papermill": {
     "duration": 0.024018,
     "end_time": "2025-11-26T04:59:47.073245",
     "exception": false,
     "start_time": "2025-11-26T04:59:47.049227",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Deduplication, Imputation, Conversion, and Drop Tools defined successfully ---\n"
     ]
    }
   ],
   "source": [
    "def tool_deduplicate(df: pd.DataFrame, column: Optional[str] = None, method: str = 'all') -> Tuple[pd.DataFrame, Dict[str, Any]]:\n",
    "    \"\"\"Removes duplicate rows.\"\"\"\n",
    "    initial_rows = len(df)\n",
    "    df_out = df.drop_duplicates(subset=[column] if column else None, keep='first')\n",
    "    rows_dropped = initial_rows - len(df_out)\n",
    "    return df_out, {'rows_dropped_dedupe': rows_dropped}\n",
    "\n",
    "def tool_impute_missing(df: pd.DataFrame, column: str, method: str) -> Tuple[pd.DataFrame, Dict[str, Any]]:\n",
    "    \"\"\"Imputes missing values in a specified column.\"\"\"\n",
    "    if column not in df.columns:\n",
    "        return df, {'impute_status': f\"Column '{column}' not found.\"}\n",
    "    \n",
    "    df_temp = df.copy() \n",
    "    missing_before = df_temp[column].isnull().sum()\n",
    "    fill_value = None\n",
    "    \n",
    "    # 1. Determine the fill value based on the method\n",
    "    if method == 'median' and pd.api.types.is_numeric_dtype(df_temp[column]):\n",
    "        fill_value = df_temp[column].median()\n",
    "    elif method == 'mean' and pd.api.types.is_numeric_dtype(df_temp[column]):\n",
    "        fill_value = df_temp[column].mean()\n",
    "    elif method == 'most_frequent':\n",
    "        mode_val = df_temp[column].mode()\n",
    "        # Fallback to a string placeholder if mode is empty \n",
    "        fill_value = mode_val[0] if not mode_val.empty else 'Unknown' \n",
    "    else:\n",
    "        return df, {'impute_status': f\"Imputation method '{method}' is not supported for dtype or column type.\"}\n",
    "    \n",
    "    # 2. Apply the imputation\n",
    "    df_temp[column] = df_temp[column].fillna(fill_value)\n",
    "    \n",
    "    # 3. Calculate metrics\n",
    "    missing_after = df_temp[column].isnull().sum()\n",
    "    imputed_count = missing_before - missing_after\n",
    "    \n",
    "    return df_temp, {'imputed_count': int(imputed_count)}\n",
    "def tool_convert_datatype(df: pd.DataFrame, column: str, method: str) -> Tuple[pd.DataFrame, Dict[str, Any]]:\n",
    "    \"\"\"Converts a column to a specified data type, dropping rows that fail conversion.\"\"\"\n",
    "    if column not in df.columns:\n",
    "        return df, {'convert_status': f\"Column '{column}' not found.\"}\n",
    "    \n",
    "    df_temp = df.copy()\n",
    "    initial_null_count = df_temp[column].isnull().sum()\n",
    "    \n",
    "    if method == 'datetime':\n",
    "        # Errors='coerce' turns non-parsable values into NaT (Not a Time)\n",
    "        df_temp['temp_col'] = pd.to_datetime(df_temp[column], errors='coerce') \n",
    "        \n",
    "    elif method == 'numeric':\n",
    "        # Errors='coerce' turns non-parsable values into NaN (Not a Number)\n",
    "        df_temp['temp_col'] = pd.to_numeric(df_temp[column], errors='coerce')\n",
    "        \n",
    "    else:\n",
    "        return df, {'convert_status': f\"Unsupported conversion method '{method}'\"}\n",
    "\n",
    "    # Calculate rows dropped due to bad formatting (new NaT/NaNs)\n",
    "    final_null_count = df_temp['temp_col'].isnull().sum()\n",
    "    rows_dropped = final_null_count - initial_null_count\n",
    "    \n",
    "    # Filter out the newly generated NaT/NaNs due to bad format\n",
    "    df_out = df_temp[df_temp['temp_col'].notnull()].copy()\n",
    "    df_out[column] = df_out.pop('temp_col')\n",
    "\n",
    "    return df_out, {'rows_dropped_conversion': int(rows_dropped)}\n",
    "def tool_drop_column(df: pd.DataFrame, column: str, method: str) -> Tuple[pd.DataFrame, Dict[str, Any]]:\n",
    "    \"\"\"Drops a column entirely (if column is specified) or drops sparse columns (if ALL and method='missing_gt_X').\"\"\"\n",
    "    \n",
    "    # 1. SPARSE COLUMN DROP (Intelligent/Data-Driven)\n",
    "    if column == \"ALL\" and method.startswith(\"missing_gt_\"):\n",
    "        try:\n",
    "            # Extract threshold percentage (e.g., 'missing_gt_75' -> 0.75)\n",
    "            threshold_percent = int(method.split('_')[-1]) / 100\n",
    "        except ValueError:\n",
    "            return df, {'drop_status': f\"Invalid threshold in method '{method}'\"}\n",
    "\n",
    "        initial_cols = df.shape[1]\n",
    "        threshold_rows = threshold_percent * len(df)\n",
    "        \n",
    "        # Identify columns where NaN count exceeds the threshold\n",
    "        cols_to_drop = df.columns[df.isnull().sum() > threshold_rows].tolist()\n",
    "        \n",
    "        if cols_to_drop:\n",
    "            df_out = df.drop(columns=cols_to_drop)\n",
    "            cols_dropped_count = initial_cols - df_out.shape[1]\n",
    "            return df_out, {'columns_dropped_sparse': cols_dropped_count, 'dropped_names': cols_to_drop}\n",
    "        else:\n",
    "            return df, {'columns_dropped_sparse': 0}\n",
    "\n",
    "    # 2. EXPLICIT COLUMN DROP\n",
    "    elif column in df.columns:\n",
    "        # Standard explicit column drop\n",
    "        df_out = df.drop(columns=[column])\n",
    "        return df_out, {'columns_dropped_explicit': 1, 'dropped_names': [column]}\n",
    "        \n",
    "    # 3. FAILURE/ERROR\n",
    "    return df, {'drop_status': f\"Column '{column}' not found or unsupported drop method.\"}\n",
    "print(\"--- Deduplication, Imputation, Conversion, and Drop Tools defined successfully ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2862ac6",
   "metadata": {
    "papermill": {
     "duration": 0.006143,
     "end_time": "2025-11-26T04:59:47.085820",
     "exception": false,
     "start_time": "2025-11-26T04:59:47.079677",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Conversion and Standardization Tools\n",
    "\n",
    "*Includes functions to handle structural issues, converting columns to correct data types like datetime or numeric, and standardizing text casing (title, lower, upper) for consistency.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19428e03",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T04:59:47.099973Z",
     "iopub.status.busy": "2025-11-26T04:59:47.099210Z",
     "iopub.status.idle": "2025-11-26T04:59:47.107339Z",
     "shell.execute_reply": "2025-11-26T04:59:47.106510Z"
    },
    "papermill": {
     "duration": 0.016883,
     "end_time": "2025-11-26T04:59:47.108787",
     "exception": false,
     "start_time": "2025-11-26T04:59:47.091904",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Conversion and Standardization Tools defined successfully ---\n"
     ]
    }
   ],
   "source": [
    "def tool_standardize_case(df: pd.DataFrame, column: str, method: str) -> Tuple[pd.DataFrame, Dict[str, Any]]:\n",
    "    \"\"\"Applies a specified case transformation (lower, upper, title) to a text column, preserving NaN values.\"\"\"\n",
    "    if column not in df.columns:\n",
    "        return df, {'case_status': f\"Column '{column}' not found.\"}\n",
    "    \n",
    "    # 1. Check if the column is a string type (or object)\n",
    "    if not (pd.api.types.is_object_dtype(df[column]) or pd.api.types.is_string_dtype(df[column])):\n",
    "        return df, {'case_status': f\"Skipped: Column '{column}' is not a string type.\"}\n",
    "\n",
    "    df_temp = df.copy()\n",
    "    initial_unique_count = df_temp[column].nunique(dropna=False) # Count NaNs as unique\n",
    "    \n",
    "    # 2. Convert to string and apply case transformation\n",
    "    series = df_temp[column].astype(str)\n",
    "    \n",
    "    if method == 'lowercase':\n",
    "        df_temp[column] = series.str.lower()\n",
    "    elif method == 'uppercase':\n",
    "        df_temp[column] = series.str.upper()\n",
    "    elif method == 'titlecase':\n",
    "        df_temp[column] = series.str.title()\n",
    "    else:\n",
    "        return df, {'case_status': f\"Unsupported case method: {method}\"}\n",
    "\n",
    "    # 3. CRITICAL STEP from Impl. 2: Convert the literal 'nan' string back to proper np.nan\n",
    "    df_temp[column] = df_temp[column].replace({'nan': np.nan})\n",
    "    \n",
    "    # 4. Metric calculation from Impl. 1\n",
    "    final_unique_count = df_temp[column].nunique(dropna=False)\n",
    "    reduction = initial_unique_count - final_unique_count\n",
    "    \n",
    "    return df_temp, {\n",
    "        'unique_reduction_case': reduction, \n",
    "        'method_applied': method,\n",
    "        'case_status': f\"Case standardized to {method}\"\n",
    "    }\n",
    "print(\"--- Conversion and Standardization Tools defined successfully ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6dc0d63",
   "metadata": {
    "papermill": {
     "duration": 0.007355,
     "end_time": "2025-11-26T04:59:47.122472",
     "exception": false,
     "start_time": "2025-11-26T04:59:47.115117",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Tool Mapping\n",
    "\n",
    "*This dictionary maps the standardized operation names (defined in the CleaningAction Pydantic model) to the corresponding tool functions for dynamic execution.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc12228f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T04:59:47.136459Z",
     "iopub.status.busy": "2025-11-26T04:59:47.136125Z",
     "iopub.status.idle": "2025-11-26T04:59:47.140536Z",
     "shell.execute_reply": "2025-11-26T04:59:47.139751Z"
    },
    "papermill": {
     "duration": 0.013085,
     "end_time": "2025-11-26T04:59:47.141912",
     "exception": false,
     "start_time": "2025-11-26T04:59:47.128827",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Map of tool names to functions\n",
    "TOOL_MAP: Dict[str, Callable] = {\n",
    "    'deduplicate': tool_deduplicate,\n",
    "    'impute_missing': tool_impute_missing,\n",
    "    'convert_datatype': tool_convert_datatype,\n",
    "    'standardize_case': tool_standardize_case,\n",
    "    'drop_column': tool_drop_column,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40af7185",
   "metadata": {
    "papermill": {
     "duration": 0.006223,
     "end_time": "2025-11-26T04:59:47.154576",
     "exception": false,
     "start_time": "2025-11-26T04:59:47.148353",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Executor Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9350c603",
   "metadata": {
    "papermill": {
     "duration": 0.00613,
     "end_time": "2025-11-26T04:59:47.166886",
     "exception": false,
     "start_time": "2025-11-26T04:59:47.160756",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "*The executor_agent_execute function sequentially processes the LLM's cleaning plan, dynamically calling the appropriate tool functions from the TOOL_MAP to perform all data transformations.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "322022cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T04:59:47.180708Z",
     "iopub.status.busy": "2025-11-26T04:59:47.180395Z",
     "iopub.status.idle": "2025-11-26T04:59:47.187955Z",
     "shell.execute_reply": "2025-11-26T04:59:47.187014Z"
    },
    "papermill": {
     "duration": 0.016176,
     "end_time": "2025-11-26T04:59:47.189208",
     "exception": false,
     "start_time": "2025-11-26T04:59:47.173032",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Executor Agent Logic Defined ---\n"
     ]
    }
   ],
   "source": [
    "def executor_agent_execute(df_raw: pd.DataFrame, cleaning_plan: CleaningPlan) -> pd.DataFrame:\n",
    "    \"\"\"Executes the cleaning plan, returning the cleaned DataFrame.\"\"\"\n",
    "    print(\"\\n--- Executor Agent (The Doer) Activated ---\")\n",
    "    df_cleaned = df_raw.copy() \n",
    "    \n",
    "    for i, action in enumerate(cleaning_plan.actions):\n",
    "        tool_name = action.operation\n",
    "        \n",
    "        if tool_name in TOOL_MAP:\n",
    "            tool_func = TOOL_MAP[tool_name]\n",
    "            \n",
    "            kwargs = {}\n",
    "            # Pass column if present (it's Optional in Pydantic)\n",
    "            if action.column is not None:\n",
    "                kwargs['column'] = action.column\n",
    "            \n",
    "            # Pass method (it's required in Pydantic, but this ensures it's available)\n",
    "            kwargs['method'] = action.method\n",
    "            try:\n",
    "                df_cleaned, metrics = tool_func(df_cleaned, **kwargs)\n",
    "                print(f\" > Executed {i+1}: {tool_name} on {action.column if action.column else 'DataFrame'} ({action.method}).\")\n",
    "                action.execution_metrics = metrics \n",
    "            except Exception as e:\n",
    "                print(f\"!!! EXECUTION FAILED for {tool_name} on {action.column}: {e}\")\n",
    "                action.execution_metrics = {'error': str(e)}\n",
    "        else:\n",
    "            print(f\"!!! Executor: Unknown operation '{tool_name}' in plan. Skipping action {i+1}.\")\n",
    "            action.execution_metrics = {'error': f\"Unknown tool: {tool_name}\"}\n",
    "\n",
    "    return df_cleaned\n",
    "\n",
    "print(\"--- Executor Agent Logic Defined ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614b59df",
   "metadata": {
    "papermill": {
     "duration": 0.006178,
     "end_time": "2025-11-26T04:59:47.201817",
     "exception": false,
     "start_time": "2025-11-26T04:59:47.195639",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "# Verifier Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0f9bcf",
   "metadata": {
    "papermill": {
     "duration": 0.006127,
     "end_time": "2025-11-26T04:59:47.214125",
     "exception": false,
     "start_time": "2025-11-26T04:59:47.207998",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "*The Verifier Agent is the quality assurance step, comparing the raw and cleaned data to generate a final VerificationReport. It calculates the confidence score based on null reduction, row loss, and execution success, providing a recommendation for the data's usability.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a73fd317",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T04:59:47.229087Z",
     "iopub.status.busy": "2025-11-26T04:59:47.228802Z",
     "iopub.status.idle": "2025-11-26T04:59:47.238609Z",
     "shell.execute_reply": "2025-11-26T04:59:47.237679Z"
    },
    "papermill": {
     "duration": 0.018889,
     "end_time": "2025-11-26T04:59:47.239900",
     "exception": false,
     "start_time": "2025-11-26T04:59:47.221011",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Verifier Agent Logic Defined ---\n"
     ]
    }
   ],
   "source": [
    "def verifier_agent_execute(df_raw: pd.DataFrame, df_cleaned: pd.DataFrame, cleaning_plan: CleaningPlan) -> VerificationReport:\n",
    "    \"\"\"[Verifier Agent] Compares raw and cleaned data and generates the final report.\"\"\"\n",
    "    print(\"\\n--- Verifier Agent (Quality Assurance) Activated ---\")\n",
    "\n",
    "    raw_rows = len(df_raw)\n",
    "    cleaned_rows = len(df_cleaned)\n",
    "    # Ensure null counts are cast to standard Python integers/floats immediately\n",
    "    raw_nulls = df_raw.isnull().sum().sum()\n",
    "    cleaned_nulls = df_cleaned.isnull().sum().sum()\n",
    "    \n",
    "    # Calculate key metrics\n",
    "    rows_dropped_total = raw_rows - cleaned_rows\n",
    "    nulls_removed = raw_nulls - cleaned_nulls\n",
    "\n",
    "    summary = {\n",
    "        'initial_rows': raw_rows,\n",
    "        'final_rows': cleaned_rows,\n",
    "        'rows_dropped_total': rows_dropped_total,\n",
    "        'initial_null_count': int(raw_nulls),\n",
    "        'final_null_count': int(cleaned_nulls),\n",
    "        'nulls_removed': int(nulls_removed),\n",
    "        'actions_performed': [f\"{a.operation}({a.column or 'df'}, {a.method})\" for a in cleaning_plan.actions]\n",
    "    }\n",
    "    \n",
    "    flags: List[str] = []\n",
    "    \n",
    "    # 1. Check for Excessive Row Deletion\n",
    "    row_loss_percent = (rows_dropped_total / raw_rows) * 100 if raw_rows > 0 else 0\n",
    "    if row_loss_percent > 15:\n",
    "        flags.append(f\"WARNING: High row deletion ({row_loss_percent:.1f}%) detected.\")\n",
    "        \n",
    "    # 2. Check for Execution Errors\n",
    "    for action in cleaning_plan.actions:\n",
    "        metrics = action.execution_metrics\n",
    "        if 'error' in metrics:\n",
    "            flags.append(f\"ERROR: Execution failed for {action.operation} on {action.column}: {metrics['error']}\")\n",
    "            \n",
    "    # 3. Determine Confidence Score (Max 1.0)\n",
    "    score = 0.0\n",
    "    \n",
    "    # a) Null Reduction (Max 50 points, scaled to 0.5)\n",
    "    if raw_nulls > 0:\n",
    "        # Ratio is capped at 1.0 (if all nulls are removed)\n",
    "        null_reduction_ratio = min(1.0, nulls_removed / raw_nulls)\n",
    "    else:\n",
    "        # If there were no raw nulls, assume 100% success (ratio = 1.0)\n",
    "        null_reduction_ratio = 1.0\n",
    "        \n",
    "    score += 0.5 * null_reduction_ratio # Max 0.5\n",
    "        \n",
    "    # b) Row Loss Penalty/Reward (Max 30 points, scaled to 0.3)\n",
    "    if row_loss_percent < 5:\n",
    "        score += 0.30 \n",
    "    elif row_loss_percent < 15:\n",
    "        score += 0.15 # Mid-level penalty\n",
    "    # If row_loss_percent >= 15, score gets 0 points from this category\n",
    "\n",
    "    # c) Execution Success (Max 20 points, scaled to 0.2)\n",
    "    if not any('ERROR' in flag for flag in flags):\n",
    "        score += 0.20 \n",
    "\n",
    "    # Final score is capped at 1.0\n",
    "    confidence_score = min(1.0, score)\n",
    "\n",
    "    # 4. Final Recommendation\n",
    "    if confidence_score > 0.85:\n",
    "        recommendation = \"Data quality is excellent. Ready for machine learning model training.\"\n",
    "    elif confidence_score > 0.60:\n",
    "        recommendation = \"Data quality is acceptable. Review the flags for potential minor issues before use.\"\n",
    "    else:\n",
    "        recommendation = \"Data quality is poor or plan execution failed. Manual intervention is required.\"\n",
    "\n",
    "    print(\" > Verification complete. Confidence score calculated.\")\n",
    "    \n",
    "    return VerificationReport(\n",
    "        confidence_score=confidence_score,\n",
    "        summary_of_changes=summary,\n",
    "        flags=flags,\n",
    "        recommendation=recommendation\n",
    "    )\n",
    "\n",
    "print(\"--- Verifier Agent Logic Defined ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e876945",
   "metadata": {
    "papermill": {
     "duration": 0.006248,
     "end_time": "2025-11-26T04:59:47.252738",
     "exception": false,
     "start_time": "2025-11-26T04:59:47.246490",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Planner Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5fd506",
   "metadata": {
    "papermill": {
     "duration": 0.006215,
     "end_time": "2025-11-26T04:59:47.265274",
     "exception": false,
     "start_time": "2025-11-26T04:59:47.259059",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "*Planner Agent attempts a live call to the Gemini LLM for zero-shot cleaning plan generation using the data profile and strict JSON schema. If the live call fails, it executes a robust, hardcoded fallback plan to guarantee a usable cleaning sequence.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3812ea44",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T04:59:47.279511Z",
     "iopub.status.busy": "2025-11-26T04:59:47.279185Z",
     "iopub.status.idle": "2025-11-26T04:59:47.286837Z",
     "shell.execute_reply": "2025-11-26T04:59:47.286044Z"
    },
    "papermill": {
     "duration": 0.016444,
     "end_time": "2025-11-26T04:59:47.288034",
     "exception": false,
     "start_time": "2025-11-26T04:59:47.271590",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Planner Agent Logic Defined ---\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------------------------------\n",
    "# 5. PLANNER AGENT LOGIC\n",
    "# ----------------------------------------------------\n",
    "\n",
    "def planner_agent_execute_adk(data_summary: Dict[str, Any]) -> CleaningPlan:\n",
    "    \"\"\"[Planner Agent - Static Version] Returns a structured CleaningPlan using a hardcoded dictionary.\"\"\"\n",
    "    print(\"\\n--- Planner Agent Activated ---\")\n",
    "    \n",
    "    # --- HARDCODED FALLBACK PLAN (The \"function json\") ---\n",
    "    fallback_plan_data = {\n",
    "        \"actions\": [\n",
    "            {\"operation\": \"deduplicate\", \"column\": \"title\", \"method\": \"first\", \"rationale\": \"Remove exact duplicate movies based on the primary identifier (Title).\"},\n",
    "            {\"operation\": \"convert_datatype\", \"column\": \"release_date\", \"method\": \"datetime\", \"rationale\": \"Ensure release date is a proper datetime format, dropping bad rows.\"},\n",
    "            \n",
    "            # Targeted Imputation for Common Nulls\n",
    "            {\"operation\": \"impute_missing\", \"column\": \"vote_average\", \"method\": \"median\", \"rationale\": \"Impute missing numerical ratings with the dataset median.\"},\n",
    "            {\"operation\": \"impute_missing\", \"column\": \"runtime\", \"method\": \"mean\", \"rationale\": \"Impute missing numerical runtimes with the mean.\"},\n",
    "            {\"operation\": \"impute_missing\", \"column\": \"overview\", \"method\": \"most_frequent\", \"rationale\": \"Impute missing text descriptions using the most common description/overview.\"},\n",
    "            {\"operation\": \"impute_missing\", \"column\": \"budget\", \"method\": \"median\", \"rationale\": \"Impute missing Budget (assuming numeric) with the median.\"},\n",
    "            \n",
    "            # Standardize text fields for quality\n",
    "            {\"operation\": \"standardize_case\", \"column\": \"genres\", \"method\": \"titlecase\", \"rationale\": \"Ensure text fields like genres are consistently formatted (Title Case).\"},\n",
    "        ]\n",
    "    }\n",
    "    # ----------------------------------------------------\n",
    "    \n",
    "    llm_response_data = fallback_plan_data\n",
    "    print(\" > Static fallback plan is active and loaded.\")\n",
    "            \n",
    "    # --- Final validation and return ---\n",
    "    if llm_response_data is None:\n",
    "        # This case should no longer be possible with the static plan\n",
    "        print(\"!!! Planner FAILED: No valid plan data available.\")\n",
    "        return CleaningPlan(actions=[])\n",
    "\n",
    "    try:\n",
    "        # Validate the static data against the Pydantic schema\n",
    "        cleaning_plan = CleaningPlan.model_validate(llm_response_data)\n",
    "        print(\" > Cleaning Plan generated and validated successfully.\")\n",
    "        print(f\" > Generated {len(cleaning_plan.actions)} cleaning actions.\")\n",
    "        return cleaning_plan\n",
    "    except Exception as e:\n",
    "        print(f\"!!! PLANNER FAILED: Plan data did not conform to the CleaningPlan schema: {e}. Returning empty plan.\")\n",
    "        return CleaningPlan(actions=[])\n",
    "print(\"--- Planner Agent Logic Defined ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02ba816",
   "metadata": {
    "papermill": {
     "duration": 0.006162,
     "end_time": "2025-11-26T04:59:47.300858",
     "exception": false,
     "start_time": "2025-11-26T04:59:47.294696",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Imp Note:**\n",
    "\n",
    "\n",
    "***Fallback Customization Instruction:** This warning ensures the hardcoded fallback plan's column names and methods are manually updated when changing datasets, guaranteeing the fallback remains logically relevant.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4926d763",
   "metadata": {
    "papermill": {
     "duration": 0.006205,
     "end_time": "2025-11-26T04:59:47.313445",
     "exception": false,
     "start_time": "2025-11-26T04:59:47.307240",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Main Pipeline Execution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa6ab24",
   "metadata": {
    "papermill": {
     "duration": 0.006137,
     "end_time": "2025-11-26T04:59:47.325814",
     "exception": false,
     "start_time": "2025-11-26T04:59:47.319677",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "*This function (run_pipeline) orchestrates the entire multi-agent process, executing the Loader, Profiler, Planner, Executor, and Verifier in sequence, concluding by displaying a detailed final verification report and saving the cleaned data.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "85f7acbb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T04:59:47.340142Z",
     "iopub.status.busy": "2025-11-26T04:59:47.339478Z",
     "iopub.status.idle": "2025-11-26T04:59:47.761856Z",
     "shell.execute_reply": "2025-11-26T04:59:47.760955Z"
    },
    "papermill": {
     "duration": 0.431758,
     "end_time": "2025-11-26T04:59:47.763800",
     "exception": false,
     "start_time": "2025-11-26T04:59:47.332042",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=======================================================\n",
      "  ZERO-SHOT DATA TRANSFORMATION: PIPELINE START (ADK)\n",
      "=======================================================\n",
      "--- Loader Agent Activated: Downloading dataset praveensoni06/1500-latest-movies-datasets-2025 ---\n",
      " > Dataset downloaded to: /kaggle/input/1500-latest-movies-datasets-2025\n",
      " > File found at: /kaggle/input/1500-latest-movies-datasets-2025/Latest 2025 movies Datasets.csv\n",
      " > Data loaded successfully.\n",
      " > Initial shape: (10000, 8). Detected NaN count: 291\n",
      "\n",
      "--- Profiler Agent (Observer) Activated ---\n",
      " > Data profiling complete. Summary generated for Planner Agent.\n",
      "\n",
      "--- Planner Agent Activated ---\n",
      " > Static fallback plan is active and loaded.\n",
      " > Cleaning Plan generated and validated successfully.\n",
      " > Generated 7 cleaning actions.\n",
      "\n",
      "--- Executor Agent (The Doer) Activated ---\n",
      " > Executed 1: deduplicate on title (first).\n",
      " > Executed 2: convert_datatype on release_date (datetime).\n",
      " > Executed 3: impute_missing on vote_average (median).\n",
      " > Executed 4: impute_missing on runtime (mean).\n",
      " > Executed 5: impute_missing on overview (most_frequent).\n",
      " > Executed 6: impute_missing on budget (median).\n",
      " > Executed 7: standardize_case on genres (titlecase).\n",
      "\n",
      "--- Verifier Agent (Quality Assurance) Activated ---\n",
      " > Verification complete. Confidence score calculated.\n",
      "\n",
      "=======================================================\n",
      "          A.I. DATA CLEANING VERIFICATION REPORT         \n",
      "=======================================================\n",
      "Confidence Score: 0.70\n",
      "\n",
      "Summary of Changes:\n",
      "{\n",
      "  \"initial_rows\": 10000,\n",
      "  \"final_rows\": 7548,\n",
      "  \"rows_dropped_total\": 2452,\n",
      "  \"initial_null_count\": 291,\n",
      "  \"final_null_count\": 0,\n",
      "  \"nulls_removed\": 291,\n",
      "  \"actions_performed\": [\n",
      "    \"deduplicate(title, first)\",\n",
      "    \"convert_datatype(release_date, datetime)\",\n",
      "    \"impute_missing(vote_average, median)\",\n",
      "    \"impute_missing(runtime, mean)\",\n",
      "    \"impute_missing(overview, most_frequent)\",\n",
      "    \"impute_missing(budget, median)\",\n",
      "    \"standardize_case(genres, titlecase)\"\n",
      "  ]\n",
      "}\n",
      "\n",
      "Detailed Action Metrics:\n",
      " - deduplicate (title): rows_dropped_dedupe: 2415\n",
      " - convert_datatype (release_date): rows_dropped_conversion: 0\n",
      " - impute_missing (vote_average): imputed_count: 0\n",
      " - impute_missing (runtime): impute_status: Column 'runtime' not found.\n",
      " - impute_missing (overview): imputed_count: 177\n",
      " - impute_missing (budget): impute_status: Column 'budget' not found.\n",
      " - standardize_case (genres): case_status: Column 'genres' not found.\n",
      "\n",
      "Flags/Warnings:\n",
      " - WARNING: High row deletion (24.5%) detected.\n",
      "\n",
      "Final Recommendation:\n",
      " - Data quality is acceptable. Review the flags for potential minor issues before use.\n",
      "=======================================================\n",
      "\n",
      " > Cleaned data successfully saved to: cleaned_movies_data.csv\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------------------------------\n",
    "# 6. MAIN PIPELINE EXECUTION\n",
    "# ----------------------------------------------------\n",
    "\n",
    "def run_pipeline():\n",
    "    \"\"\"Executes the entire 5-step Multi-Agent System sequentially.\"\"\"\n",
    "    print(f\"\\n=======================================================\")\n",
    "    print(f\"  ZERO-SHOT DATA TRANSFORMATION: PIPELINE START (ADK)\")\n",
    "    print(f\"=======================================================\")\n",
    "\n",
    "    # Step 1: Load Data (Loader Agent)\n",
    "    df_raw = load_data(KAGGLE_DATASET_ID, CSV_FILE_NAME)\n",
    "\n",
    "    if df_raw is None:\n",
    "        print(\"\\n*** ABORTING PIPELINE due to data loading failure. ***\")\n",
    "        return\n",
    "\n",
    "    # Step 2: Profile Data (Profiler Agent)\n",
    "    summary_raw = profile_data(df_raw)\n",
    "    \n",
    "    # Step 3: Plan Generation (Planner Agent)\n",
    "    cleaning_plan = planner_agent_execute_adk(summary_raw)\n",
    "\n",
    "    if cleaning_plan.actions:\n",
    "        # Step 4: Execution (Executor Agent)\n",
    "        df_cleaned = executor_agent_execute(df_raw, cleaning_plan)\n",
    "\n",
    "        # Step 5: Verification and Reporting (Verifier Agent)\n",
    "        verification_report = verifier_agent_execute(df_raw, df_cleaned, cleaning_plan)\n",
    "        \n",
    "        # Display Final Report\n",
    "        print(\"\\n=======================================================\")\n",
    "        print(\"          A.I. DATA CLEANING VERIFICATION REPORT         \")\n",
    "        print(\"=======================================================\")\n",
    "        print(f\"Confidence Score: {verification_report.confidence_score:.2f}\")\n",
    "        \n",
    "        print(\"\\nSummary of Changes:\")\n",
    "        print(json.dumps(verification_report.summary_of_changes, indent=2))\n",
    "        \n",
    "        print(\"\\nDetailed Action Metrics:\")\n",
    "        for action in cleaning_plan.actions:\n",
    "            metrics = action.execution_metrics\n",
    "            metric_str = \", \".join([f\"{k}: {v}\" for k, v in metrics.items()])\n",
    "            print(f\" - {action.operation} ({action.column or 'df'}): {metric_str}\")\n",
    "\n",
    "        print(\"\\nFlags/Warnings:\")\n",
    "        if verification_report.flags:\n",
    "            for flag in verification_report.flags:\n",
    "                print(f\" - {flag}\")\n",
    "        else:\n",
    "            print(\" - None\")\n",
    "            \n",
    "        print(\"\\nFinal Recommendation:\")\n",
    "        print(f\" - {verification_report.recommendation}\")\n",
    "        print(\"=======================================================\")\n",
    "\n",
    "        # Final Step: Save Results (Utility)\n",
    "        save_cleaned_data(df_cleaned, OUTPUT_FILE_PATH)\n",
    "    else:\n",
    "        print(\"\\n*** ABORTING PIPELINE: Planner failed to generate a valid plan. ***\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95479fd3",
   "metadata": {
    "papermill": {
     "duration": 0.006944,
     "end_time": "2025-11-26T04:59:47.777721",
     "exception": false,
     "start_time": "2025-11-26T04:59:47.770777",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 14448097,
     "datasetId": 8717198,
     "isSourceIdPinned": false,
     "sourceId": 13703496,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 8.491583,
   "end_time": "2025-11-26T04:59:48.302886",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-11-26T04:59:39.811303",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
